{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b4bbef-8dd3-47df-b826-b3e821d0652c",
   "metadata": {},
   "source": [
    "# Step 1 | Platform Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d4ac4-2f42-465e-ab06-be0e9e8db305",
   "metadata": {},
   "source": [
    "## Step 1.1 | Check Environment\n",
    "1. Open Anaconda Prompt\n",
    "2. conda activate tf-gpu\n",
    "3. jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71abb4d-6a56-4f49-b58c-d6a15dc0a638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tf-gpu\\python.exe\n",
      "C:\\Anaconda\\python.exe\n",
      "C:\\Anaconda\\envs\\tf-gpu\\python.exe\n",
      "2.1.0+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 4GB Laptop GPU\n",
      "4.35.2\n",
      "C:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\transformers\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "!where python\n",
    "print(sys.executable)\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(transformers.__version__)\n",
    "print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5436e4-ad68-4050-bb27-8ecedd432834",
   "metadata": {},
   "source": [
    "## Step 1.2 | Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22afccb7-e8b7-4e40-a257-ffc4e4f0e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from openai import OpenAI\n",
    "import unicodedata\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698a235-364d-4bf5-8403-f3609bbdd8ad",
   "metadata": {},
   "source": [
    "# Step 2 | Fetch News Articles (GNews API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e5e03-7786-4cca-b985-d3a9a636b276",
   "metadata": {},
   "source": [
    "## Step 2.1 | Define GNews API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98623d83-df6a-4936-aa37-68070f33a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API key here\n",
    "GNEWS_API_KEY = \"INSERT_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb6321-0161-41ff-8424-e79a074687fb",
   "metadata": {},
   "source": [
    "## Step 2.2 | Define Fetch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a96bbd-81c0-4777-a25d-93d7e3961307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_top_headlines(api_key, max_results=8):\n",
    "    \"\"\"\n",
    "    Fetches top headlines from GNews using the /top-headlines endpoint.\n",
    "\n",
    "    Parameters:\n",
    "        api_key (str): Your GNews API key\n",
    "        max_results (int): Total number of articles to return (max 10 allowed by GNews)\n",
    "\n",
    "    Returns:\n",
    "        list of dicts: Each dict contains title, description, content, source, and publishedAt\n",
    "    \"\"\"\n",
    "    base_url = \"https://gnews.io/api/v4/top-headlines\"\n",
    "    params = {\n",
    "        \"lang\": \"en\",\n",
    "        \"country\": \"us\",\n",
    "        \"max\": max_results,\n",
    "        \"apikey\": api_key\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        articles = []\n",
    "        for article in data.get(\"articles\", []):\n",
    "            articles.append({\n",
    "                \"title\": article.get(\"title\"),\n",
    "                \"description\": article.get(\"description\"),\n",
    "                \"content\": article.get(\"content\"),\n",
    "                \"source_name\": article.get(\"source\", {}).get(\"name\"),\n",
    "                \"publishedAt\": article.get(\"publishedAt\"),\n",
    "                \"url\": article.get(\"url\")\n",
    "            })\n",
    "\n",
    "        return articles\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching top headlines:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f786a7f-9003-4aa2-941d-67915852e917",
   "metadata": {},
   "source": [
    "## Step 2.3 | Fetch Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d1488dc9-5fd4-4ec8-b301-69cd271ddd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 10 articles.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source_name</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jake Paul vs. Julio Cesar Chavez Jr. live resu...</td>\n",
       "      <td>Yahoo Sports</td>\n",
       "      <td>2025-06-28T23:20:43Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final party set to end Bezos-Sánchez wedding e...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>2025-06-28T22:45:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hurricane season is here and meteorologists ar...</td>\n",
       "      <td>ABC News - Breaking News, Latest News and Videos</td>\n",
       "      <td>2025-06-28T21:13:26Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warren Buffett announces $6 billion in donatio...</td>\n",
       "      <td>AP News</td>\n",
       "      <td>2025-06-28T21:04:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dave Parker, 2-time World Series champ, 7-time...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2025-06-28T20:29:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ancient city possibly ruled by females living ...</td>\n",
       "      <td>CBS News</td>\n",
       "      <td>2025-06-28T20:26:47Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Protesters line highway in Florida Everglades ...</td>\n",
       "      <td>AP News</td>\n",
       "      <td>2025-06-28T20:11:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Celebrities emerge day after Jeff Bezos, Laure...</td>\n",
       "      <td>USA Today</td>\n",
       "      <td>2025-06-28T19:42:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kneecap hit back at Starmer in highly-charged ...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>2025-06-28T18:41:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>After Supreme Court term, Chief Justice Robert...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2025-06-28T17:54:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Jake Paul vs. Julio Cesar Chavez Jr. live resu...   \n",
       "1  Final party set to end Bezos-Sánchez wedding e...   \n",
       "2  Hurricane season is here and meteorologists ar...   \n",
       "3  Warren Buffett announces $6 billion in donatio...   \n",
       "4  Dave Parker, 2-time World Series champ, 7-time...   \n",
       "5  Ancient city possibly ruled by females living ...   \n",
       "6  Protesters line highway in Florida Everglades ...   \n",
       "7  Celebrities emerge day after Jeff Bezos, Laure...   \n",
       "8  Kneecap hit back at Starmer in highly-charged ...   \n",
       "9  After Supreme Court term, Chief Justice Robert...   \n",
       "\n",
       "                                        source_name           publishedAt  \n",
       "0                                      Yahoo Sports  2025-06-28T23:20:43Z  \n",
       "1                                      The Guardian  2025-06-28T22:45:00Z  \n",
       "2  ABC News - Breaking News, Latest News and Videos  2025-06-28T21:13:26Z  \n",
       "3                                           AP News  2025-06-28T21:04:00Z  \n",
       "4                                              ESPN  2025-06-28T20:29:00Z  \n",
       "5                                          CBS News  2025-06-28T20:26:47Z  \n",
       "6                                           AP News  2025-06-28T20:11:00Z  \n",
       "7                                         USA Today  2025-06-28T19:42:04Z  \n",
       "8                                               BBC  2025-06-28T18:41:09Z  \n",
       "9                                               CNN  2025-06-28T17:54:00Z  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch today's top headlines\n",
    "all_articles = fetch_top_headlines(GNEWS_API_KEY, max_results=25)\n",
    "\n",
    "# Check the result\n",
    "print(f\"Fetched {len(all_articles)} articles.\")\n",
    "pd.DataFrame(all_articles)[[\"title\", \"source_name\", \"publishedAt\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccd8f3-9524-4987-84c9-63a91362667a",
   "metadata": {},
   "source": [
    "# Step 3 | Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406c561-ba9f-4fe3-bc5c-6e296f25e6bb",
   "metadata": {},
   "source": [
    "## Step 3.1 | Convert Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "574c0bb8-d5bc-4201-a463-cb415eee1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw list to DataFrame\n",
    "df_articles = pd.DataFrame(all_articles)\n",
    "\n",
    "# Fill missing fields with empty string (for text fields)\n",
    "df_articles.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e51038a-21f0-44f0-97e3-3e428ff2b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning function for messy text encoding\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize(\"NFKC\", text)  # Normalize character width & accents\n",
    "    text = text.replace(\"â€™\", \"'\").replace(\"â€œ\", '\"').replace(\"â€�\", '\"')\n",
    "    text = text.replace(\"â€”\", \"—\").replace(\"â€“\", \"-\")\n",
    "    text = text.replace(\"Ã©\", \"é\").replace(\"Ã\", \"à\")  # Add more mappings as needed\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "837cc640-74f3-411e-afc2-59e7d9459738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the core text fields\n",
    "text_columns = [\"title\", \"description\", \"content\"]\n",
    "for col in text_columns:\n",
    "    if col in df_articles.columns:\n",
    "        df_articles[col] = df_articles[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db83ae13-164a-4914-869b-6bf5635f4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned and combined text fields\n"
     ]
    }
   ],
   "source": [
    "# Combine into full_text for clustering or embedding\n",
    "df_articles[\"full_text\"] = (\n",
    "    df_articles[\"title\"].str.strip() + \". \" +\n",
    "    df_articles[\"description\"].str.strip() + \". \" +\n",
    "    df_articles[\"content\"].str.strip()\n",
    ").str.strip()\n",
    "\n",
    "print(\"✅ Cleaned and combined text fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e126dd-ae04-4d61-a595-3be95d8ea6d3",
   "metadata": {},
   "source": [
    "## Step 3.2 | Remove Irrelevant Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3144ce75-a54b-4240-96ae-218a696e21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty or very short articles (less than 50 characters of combined text)\n",
    "df_articles = df_articles[df_articles[\"full_text\"].str.len() > 50].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a2008366-e55b-4bbd-9d3b-4f2728560531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop near-duplicates using cosine similarity\n",
    "def drop_near_duplicates(df, text_column=\"full_text\", similarity_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Drops near-duplicate rows based on cosine similarity between their text contents.\n",
    "    \"\"\"\n",
    "    texts = df[text_column].tolist()\n",
    "    tfidf = TfidfVectorizer(stop_words='english').fit_transform(texts)\n",
    "    sim_matrix = cosine_similarity(tfidf)\n",
    "    \n",
    "    to_drop = set()\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i + 1, len(texts)):\n",
    "            if sim_matrix[i, j] > similarity_threshold:\n",
    "                to_drop.add(j)\n",
    "    return df.drop(df.index[list(to_drop)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "68d15f55-b2ba-451a-b16a-a4df8661b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned down to 10 unique articles.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source_name</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jake Paul vs. Julio Cesar Chavez Jr. live resu...</td>\n",
       "      <td>Yahoo Sports</td>\n",
       "      <td>2025-06-28T23:20:43Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final party set to end Bezos-Sánchez wedding e...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>2025-06-28T22:45:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hurricane season is here and meteorologists ar...</td>\n",
       "      <td>ABC News - Breaking News, Latest News and Videos</td>\n",
       "      <td>2025-06-28T21:13:26Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warren Buffett announces $6 billion in donatio...</td>\n",
       "      <td>AP News</td>\n",
       "      <td>2025-06-28T21:04:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dave Parker, 2-time World Series champ, 7-time...</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>2025-06-28T20:29:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ancient city possibly ruled by females living ...</td>\n",
       "      <td>CBS News</td>\n",
       "      <td>2025-06-28T20:26:47Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Protesters line highway in Florida Everglades ...</td>\n",
       "      <td>AP News</td>\n",
       "      <td>2025-06-28T20:11:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Celebrities emerge day after Jeff Bezos, Laure...</td>\n",
       "      <td>USA Today</td>\n",
       "      <td>2025-06-28T19:42:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kneecap hit back at Starmer in highly-charged ...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>2025-06-28T18:41:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>After Supreme Court term, Chief Justice Robert...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2025-06-28T17:54:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Jake Paul vs. Julio Cesar Chavez Jr. live resu...   \n",
       "1  Final party set to end Bezos-Sánchez wedding e...   \n",
       "2  Hurricane season is here and meteorologists ar...   \n",
       "3  Warren Buffett announces $6 billion in donatio...   \n",
       "4  Dave Parker, 2-time World Series champ, 7-time...   \n",
       "5  Ancient city possibly ruled by females living ...   \n",
       "6  Protesters line highway in Florida Everglades ...   \n",
       "7  Celebrities emerge day after Jeff Bezos, Laure...   \n",
       "8  Kneecap hit back at Starmer in highly-charged ...   \n",
       "9  After Supreme Court term, Chief Justice Robert...   \n",
       "\n",
       "                                        source_name           publishedAt  \n",
       "0                                      Yahoo Sports  2025-06-28T23:20:43Z  \n",
       "1                                      The Guardian  2025-06-28T22:45:00Z  \n",
       "2  ABC News - Breaking News, Latest News and Videos  2025-06-28T21:13:26Z  \n",
       "3                                           AP News  2025-06-28T21:04:00Z  \n",
       "4                                              ESPN  2025-06-28T20:29:00Z  \n",
       "5                                          CBS News  2025-06-28T20:26:47Z  \n",
       "6                                           AP News  2025-06-28T20:11:00Z  \n",
       "7                                         USA Today  2025-06-28T19:42:04Z  \n",
       "8                                               BBC  2025-06-28T18:41:09Z  \n",
       "9                                               CNN  2025-06-28T17:54:00Z  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply deduplication\n",
    "df_articles_clean = drop_near_duplicates(df_articles)\n",
    "\n",
    "print(f\"Cleaned down to {len(df_articles_clean)} unique articles.\")\n",
    "df_articles_clean[[\"title\", \"source_name\", \"publishedAt\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28129e-da71-4662-ac12-bcd0e148f517",
   "metadata": {},
   "source": [
    "# Step 4 | Topic Clustering (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118ecd1-29e4-4084-96aa-4149f90de6c8",
   "metadata": {},
   "source": [
    "## Step 4.1 | Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b627fd9f-9a1c-4a03-a8e8-a97d18578e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the full_text\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf.fit_transform(df_articles_clean[\"full_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f073e7-bdc6-4ab3-b763-8e5036c326b1",
   "metadata": {},
   "source": [
    "## Step 4.2 | Cluster Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f889bb35-91c1-4f8a-8a8d-e94e78e7fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster into shared narratives\n",
    "num_clusters = 4\n",
    "\n",
    "clustering_model = AgglomerativeClustering(\n",
    "    n_clusters=num_clusters,\n",
    "    metric='cosine',\n",
    "    linkage='average',\n",
    "    compute_full_tree=True\n",
    ")\n",
    "\n",
    "cluster_labels = clustering_model.fit_predict(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ba579-d02b-4a05-9eee-5c75cfef8b81",
   "metadata": {},
   "source": [
    "## Step 4.3 | Add Cluster Labels to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4d2da06-bb89-439d-b919-da187e3377ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>title</th>\n",
       "      <th>source_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jake Paul vs. Julio Cesar Chavez Jr. live resu...</td>\n",
       "      <td>Yahoo Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Final party set to end Bezos-Sánchez wedding e...</td>\n",
       "      <td>The Guardian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Dave Parker, 2-time World Series champ, 7-time...</td>\n",
       "      <td>ESPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Ancient city possibly ruled by females living ...</td>\n",
       "      <td>CBS News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Celebrities emerge day after Jeff Bezos, Laure...</td>\n",
       "      <td>USA Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Kneecap hit back at Starmer in highly-charged ...</td>\n",
       "      <td>BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>After Supreme Court term, Chief Justice Robert...</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Warren Buffett announces $6 billion in donatio...</td>\n",
       "      <td>AP News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Protesters line highway in Florida Everglades ...</td>\n",
       "      <td>AP News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hurricane season is here and meteorologists ar...</td>\n",
       "      <td>ABC News - Breaking News, Latest News and Videos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                              title  \\\n",
       "0        0  Jake Paul vs. Julio Cesar Chavez Jr. live resu...   \n",
       "1        0  Final party set to end Bezos-Sánchez wedding e...   \n",
       "4        0  Dave Parker, 2-time World Series champ, 7-time...   \n",
       "5        0  Ancient city possibly ruled by females living ...   \n",
       "7        0  Celebrities emerge day after Jeff Bezos, Laure...   \n",
       "8        0  Kneecap hit back at Starmer in highly-charged ...   \n",
       "9        0  After Supreme Court term, Chief Justice Robert...   \n",
       "3        1  Warren Buffett announces $6 billion in donatio...   \n",
       "6        2  Protesters line highway in Florida Everglades ...   \n",
       "2        3  Hurricane season is here and meteorologists ar...   \n",
       "\n",
       "                                        source_name  \n",
       "0                                      Yahoo Sports  \n",
       "1                                      The Guardian  \n",
       "4                                              ESPN  \n",
       "5                                          CBS News  \n",
       "7                                         USA Today  \n",
       "8                                               BBC  \n",
       "9                                               CNN  \n",
       "3                                           AP News  \n",
       "6                                           AP News  \n",
       "2  ABC News - Breaking News, Latest News and Videos  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach cluster labels back to your cleaned DataFrame\n",
    "df_articles_clean[\"cluster\"] = cluster_labels\n",
    "\n",
    "# Preview\n",
    "df_articles_clean[[\"cluster\", \"title\", \"source_name\"]].sort_values(\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638584bd-6b30-42c8-8f1d-ab176e4c4435",
   "metadata": {},
   "source": [
    "# Step 5 | Prompt Generator (OpenRouter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb06b43-f48a-4992-b11a-416f2cdf40dd",
   "metadata": {},
   "source": [
    "## Step 5.1 | Define OpenRouter API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7addbef-7c54-49e2-b849-4a9f5eb9380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAI-compatible client using OpenRouter settings\n",
    "client = OpenAI(\n",
    "    api_key=\"INSERT_KEY_HERE\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\"  # required for OpenRouter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641b8a9-483f-49fb-9b3a-4805fa0e7368",
   "metadata": {},
   "source": [
    "## Step 5.2 | Define LLM Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "38d82bd0-6054-4358-bc19-7d038829f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of OpenRouter LLMs\n",
    "# models = client.models.list()\n",
    "# for m in models.data:\n",
    "#     print(m.id)\n",
    "# \"\"\"\n",
    "# \"openai/gpt-4o\"\n",
    "# \"microsoft/mai-ds-r1:free\"\n",
    "# \"google/gemini-2.0-flash-exp:free\"\n",
    "# \"minimax/minimax-m1:extended\"\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84419eec-00cc-4acd-bb37-a201e91834b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "LLM_MODEL = \"microsoft/mai-ds-r1:free\"   # Swap in any free OpenRouter model here\n",
    "\n",
    "# Content chunking\n",
    "max_content_chars = 1000                  # Characters of content to include per article in the prompt\n",
    "\n",
    "# Generation parameters\n",
    "max_tokens = 2000                        # Maximum tokens returned by the LLM per response\n",
    "temperature = 0.7                        # Higher = more creative, lower = more focused and safe\n",
    "top_p = 1.0                              # Optional: nucleus sampling control (keep at 1.0 unless experimenting)\n",
    "\n",
    "# Rate limit control\n",
    "rate_limit_pause = 2.0                   # Seconds to pause between API calls to avoid rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a32eb-5220-4d3b-ab83-3aa67dfc024b",
   "metadata": {},
   "source": [
    "## Step 5.3 | Define Prompt Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475249a-e854-4d61-8d64-4199af15d708",
   "metadata": {},
   "source": [
    "Generates a reflective writing prompt for a cluster of articles.\n",
    "\n",
    "Includes title + description + trimmed content for each article to guide the LLM.\n",
    "\n",
    "**Parameters:**\n",
    "- cluster_df (pd.DataFrame): DataFrame of articles in one cluster\n",
    "- cluster_id (int): Cluster ID (for logging)\n",
    "- model (str): LLM model ID from OpenRouter\n",
    "- max_content_chars (int): Max characters to keep from article content (default: 400)\n",
    "\n",
    "**Returns:**\n",
    "- str: The generated prompt output from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "570f3b35-2340-4e7b-9a9d-7afe24390206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_for_cluster(cluster_df, cluster_id, model=LLM_MODEL, max_content_chars=max_content_chars, top_p=top_p):\n",
    "\n",
    "    \"\"\"\n",
    "    EXTRACT TEXT FROM EACH ARTICLE IN CLUSTER\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    for _, row in cluster_df.iterrows():\n",
    "        title = row.get(\"title\", \"\").strip()\n",
    "        description = row.get(\"description\", \"\").strip()\n",
    "        content = row.get(\"content\", \"\").strip()[:max_content_chars]\n",
    "\n",
    "        entry_text = f\"- {title}: {description} {content}\".strip()\n",
    "        entries.append(entry_text)\n",
    "\n",
    "    headlines_text = \"\\n\".join(entries)\n",
    "\n",
    "    \"\"\"\n",
    "    INPUT PROMPT HERE\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Here are 2–3 articles or headlines about a current event:\n",
    "\n",
    "{headlines_text}\n",
    "\n",
    "I’m writing a reflective piece in the “Politics for the Tired” style. Please:\n",
    "\n",
    "- Summarize what happened in emotionally neutral terms\n",
    "- Identify 2–3 emotions a thoughtful, tired reader might feel\n",
    "- Name 1–2 moral or identity-based tensions\n",
    "- Suggest a soft narrative arc for an essay\n",
    "- Propose a working title and subtitle that evoke the emotional truth, not just the facts\n",
    "\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    CALL LLM API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,  # Keep outputs token-efficient\n",
    "            top_p=top_p\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"ERROR generating prompt for cluster {cluster_id}: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b163b-ab03-45b9-ad3d-8fdc69d692ef",
   "metadata": {},
   "source": [
    "## Step 5.4 | Run LLM Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "32161ccb-3ce1-4a27-bc3c-ddc639263e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort clusters by number of articles (descending)\n",
    "cluster_sizes = (\n",
    "    df_articles_clean[\"cluster\"]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .index.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "17a6c7e8-e78e-4773-866a-45636d5bbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Run LLM prompt generation in sorted order\n",
    "clustered_prompts = []\n",
    "\n",
    "for cluster_id in cluster_sizes:\n",
    "    cluster_df = df_articles_clean[df_articles_clean[\"cluster\"] == cluster_id]\n",
    "    output = generate_prompt_for_cluster(cluster_df, cluster_id)\n",
    "    \n",
    "    clustered_prompts.append({\n",
    "        \"cluster\": cluster_id,\n",
    "        \"headlines\": \"\\n\".join(cluster_df[\"title\"].tolist()),\n",
    "        \"prompt_output\": output\n",
    "    })\n",
    "\n",
    "    # Pause to avoid hitting rate limits\n",
    "    time.sleep(rate_limit_pause)\n",
    "\n",
    "# Step 3: Create final DataFrame\n",
    "df_prompts = pd.DataFrame(clustered_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9167f-b6b0-4645-9a39-6d1ff43a0a46",
   "metadata": {},
   "source": [
    "## Step 5.5 | Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5af3db4f-8c41-4209-a4e8-f4baea35abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parameters to track ===\n",
    "parameters_used = {\n",
    "    \"LLM_Model\": LLM_MODEL,\n",
    "    \"max_content_chars\": max_content_chars,\n",
    "    \"max_tokens\": max_tokens,\n",
    "    \"temperature\": temperature,\n",
    "    \"top_p\": top_p,\n",
    "    \"rate_limit_pause\": rate_limit_pause\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "321a4d32-0b0f-4641-ab2b-c0d1a8ac8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Create filename with versioning ===\n",
    "base_filename = \"narrative_prompts\"\n",
    "existing_files = [f for f in os.listdir() if f.startswith(base_filename) and f.endswith(\".xlsx\")]\n",
    "\n",
    "if f\"{base_filename}.xlsx\" not in existing_files:\n",
    "    filename = f\"{base_filename}.xlsx\"\n",
    "else:\n",
    "    version = 1\n",
    "    while f\"{base_filename}_{version}.xlsx\" in existing_files:\n",
    "        version += 1\n",
    "    filename = f\"{base_filename}_{version}.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ffb0f19a-bc19-4636-831d-8b787c8f8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 2: Create parameter DataFrame ===\n",
    "df_params = pd.DataFrame(list(parameters_used.items()), columns=[\"Parameter\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4da7ae33-d834-4fab-b54c-7dca5df41965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 3: Write both DataFrames to Excel ===\n",
    "with pd.ExcelWriter(filename, engine=\"openpyxl\") as writer:\n",
    "    df_prompts.to_excel(writer, sheet_name=\"Prompts\", index=False)\n",
    "    df_params.to_excel(writer, sheet_name=\"Parameters\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c9fd1e6e-a1b5-49dc-a899-f87da3f3b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompts and parameters saved to narrative_prompts_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "# === Step 4 (optional): Set font style in Excel ===\n",
    "wb = load_workbook(filename)\n",
    "font = Font(name=\"Aptos Narrow\", size=11)\n",
    "\n",
    "for sheet in wb.sheetnames:\n",
    "    ws = wb[sheet]\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.font = font\n",
    "\n",
    "wb.save(filename)\n",
    "\n",
    "print(f\"✅ Prompts and parameters saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4fb1e-371f-4895-9719-ea17f5583f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94463d2-63c5-4eed-9fc9-b04f39c3cd93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
